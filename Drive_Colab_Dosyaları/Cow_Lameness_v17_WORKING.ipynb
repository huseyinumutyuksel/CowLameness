{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "header"
            },
            "source": [
                "# \ud83d\udc04 Cow Lameness Detection - Complete Pipeline v17\n",
                "**MMPose + SAM - Training, Validation & Inference**\n",
                "\n",
                "## Pipeline\n",
                "1. **Training**: MMPose pose estimation \u2192 Feature extraction \u2192 5-Fold CV\n",
                "2. **Inference**: Classify new videos \u2192 SAM masking \u2192 Clinical report\n",
                "\n",
                "**\u26a0\ufe0f IMPORTANT**: GPU gerekli (Runtime \u2192 Change runtime type \u2192 GPU)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Installation (\u0130lk \u00e7al\u0131\u015ft\u0131rmada 3-5 dakika s\u00fcrer)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, sys\n",
                "\n",
                "def install_and_restart():\n",
                "    print(\"\ud83d\udce6 Checking dependencies...\")\n",
                "    try:\n",
                "        import mmpose\n",
                "        import mmdet\n",
                "        import mmcv\n",
                "        print(\"\u2705 Libraries already installed! Skipping setup.\")\n",
                "    except ImportError:\n",
                "        print(\"\u2699\ufe0f Libraries not found. Installing now... (This takes ~3-5 mins)\")\n",
                "        \n",
                "        # 1. Install OpenMIM\n",
                "        !pip install -U openmim\n",
                "        \n",
                "        # 2. Install MMLab packages using python -m mim\n",
                "        !python -m mim install mmengine\n",
                "        !python -m mim install \"mmcv>=2.0.0\"\n",
                "        !python -m mim install \"mmdet>=3.0.0\"\n",
                "        !python -m mim install \"mmpose>=1.0.0\"\n",
                "        \n",
                "        # 3. Install other dependencies\n",
                "        !pip install -q opencv-python scikit-learn matplotlib seaborn tqdm joblib\n",
                "        !pip install -q git+https://github.com/facebookresearch/segment-anything.git\n",
                "        \n",
                "        # 4. Download SAM checkpoint if missing\n",
                "        if not os.path.exists('sam_vit_b.pth'):\n",
                "            !wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth -O sam_vit_b.pth\n",
                "        \n",
                "        print(\"\\n\ud83d\udd04 Installation complete. Restarting runtime automatically...\")\n",
                "        os.kill(os.getpid(), 9)\n",
                "\n",
                "install_and_restart()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Imports & Setup (Runtime restart sonras\u0131 buradan ba\u015flay\u0131n)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "import os, glob, joblib\n",
                "import numpy as np\n",
                "import torch\n",
                "import cv2\n",
                "from tqdm import tqdm\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from collections import defaultdict\n",
                "\n",
                "from mmpose.apis import MMPoseInferencer\n",
                "from segment_anything import sam_model_registry, SamPredictor\n",
                "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.metrics import *\n",
                "\n",
                "# Paths\n",
                "BASE = \"/content/drive/MyDrive/Inek Topallik Tespiti Parcalanmis Inek Videolari\"\n",
                "DATA = f\"{BASE}/cow_single_videos\"\n",
                "OUT = f\"{BASE}/outputs_v17_mmpose\"\n",
                "MULTI = f\"{BASE}/Raw_MultiCow_Videos\"\n",
                "\n",
                "for d in [\"models\", \"embeddings\", \"metrics\", \"figures\", \"inference_videos\"]:\n",
                "    os.makedirs(f\"{OUT}/{d}\", exist_ok=True)\n",
                "\n",
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "print(f\"Device: {device}\")\n",
                "\n",
                "# Get training videos\n",
                "all_videos = []\n",
                "for label in ['Saglikli', 'Topal']:\n",
                "    folder = os.path.join(DATA, label)\n",
                "    if os.path.exists(folder):\n",
                "        vids = glob.glob(f\"{folder}/*.mp4\")\n",
                "        all_videos.extend([(v, 0 if label=='Saglikli' else 1) for v in vids])\n",
                "        print(f\"\u2713 {len(vids)} {label} videos\")\n",
                "\n",
                "print(f\"\\nTotal: {len(all_videos)} videos\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Load Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Loading MMPose...\")\n",
                "pose_inf = MMPoseInferencer(pose2d='animal')\n",
                "print(\"\u2705 MMPose loaded\\n\")\n",
                "\n",
                "print(\"Loading SAM...\")\n",
                "sam = sam_model_registry[\"vit_b\"](checkpoint=\"sam_vit_b.pth\").to(device)\n",
                "sam_pred = SamPredictor(sam)\n",
                "print(\"\u2705 SAM loaded\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Feature Extraction Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def extract_pose_seq(vid_path, max_f=100, skip=3):\n",
                "    cap = cv2.VideoCapture(vid_path)\n",
                "    if not cap.isOpened(): return None\n",
                "    poses, idx, proc = [], 0, 0\n",
                "    while proc < max_f:\n",
                "        ret, frame = cap.read()\n",
                "        if not ret: break\n",
                "        if idx % skip != 0:\n",
                "            idx += 1\n",
                "            continue\n",
                "        idx += 1\n",
                "        proc += 1\n",
                "        try:\n",
                "            res = next(pose_inf(frame, show=False, return_vis=False))\n",
                "            if res['predictions'] and res['predictions'][0]:\n",
                "                p = res['predictions'][0][0]\n",
                "                kpts = np.column_stack([p['keypoints'], p['keypoint_scores']])\n",
                "                poses.append(kpts)\n",
                "            else:\n",
                "                poses.append(np.zeros((17,3)))\n",
                "        except:\n",
                "            poses.append(np.zeros((17,3)))\n",
                "    cap.release()\n",
                "    return np.array(poses) if len(poses)>=5 else None\n",
                "\n",
                "def motion_feats(pose_seq):\n",
                "    if pose_seq is None or len(pose_seq)<2: return None\n",
                "    pos = pose_seq[:,:,:2]\n",
                "    conf = pose_seq[:,:,2]\n",
                "    vel = np.diff(pos, axis=0)\n",
                "    mag = np.linalg.norm(vel, axis=2).mean(axis=1)\n",
                "    return np.concatenate([\n",
                "        pos.mean(0).flatten(), pos.std(0).flatten(),\n",
                "        vel.mean(0).flatten(), vel.std(0).flatten(),\n",
                "        [mag.mean(), mag.std(), mag.max(), mag.min()],\n",
                "        conf.mean(0)\n",
                "    ])\n",
                "\n",
                "def gait_angles(pose_seq):\n",
                "    if pose_seq is None: return np.zeros(12)\n",
                "    def ang(a,b,c):\n",
                "        ba,bc = a-b, c-b\n",
                "        cos = np.dot(ba,bc)/(np.linalg.norm(ba)*np.linalg.norm(bc)+1e-8)\n",
                "        return np.degrees(np.arccos(np.clip(cos,-1,1)))\n",
                "    angs = []\n",
                "    for f in pose_seq:\n",
                "        k = f[:,:2]\n",
                "        try:\n",
                "            a = [ang(k[5],k[7],k[9]), ang(k[6],k[8],k[10]),\n",
                "                 ang(k[11],k[13],k[15]), ang(k[12],k[14],k[16]),\n",
                "                 ang((k[5]+k[6])/2, (k[5]+k[6]+k[11]+k[12])/4, (k[11]+k[12])/2),\n",
                "                 ang((k[3]+k[4])/2, k[0], (k[5]+k[6])/2)]\n",
                "            angs.append(a)\n",
                "        except:\n",
                "            angs.append([180]*6)\n",
                "    angs = np.array(angs)\n",
                "    return np.concatenate([angs.mean(0), angs.std(0)])\n",
                "\n",
                "def extract_features(vid_path):\n",
                "    ps = extract_pose_seq(vid_path)\n",
                "    if ps is None: return None\n",
                "    mf = motion_feats(ps)\n",
                "    ga = gait_angles(ps)\n",
                "    return np.concatenate([mf, ga]) if mf is not None else None\n",
                "\n",
                "print(\"\u2705 Feature extraction ready (169 features)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Extract Features (or load cached)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_PATH = f\"{OUT}/embeddings/X_v17.npy\"\n",
                "Y_PATH = f\"{OUT}/embeddings/y_v17.npy\"\n",
                "\n",
                "if os.path.exists(X_PATH) and os.path.exists(Y_PATH):\n",
                "    X = np.load(X_PATH)\n",
                "    y = np.load(Y_PATH)\n",
                "    print(f\"\u2705 Loaded {len(X)} cached samples\")\n",
                "else:\n",
                "    print(f\"\ud83d\udd04 Extracting features from {len(all_videos)} videos...\")\n",
                "    X, y = [], []\n",
                "    for vid, label in tqdm(all_videos, desc=\"Processing\"):\n",
                "        try:\n",
                "            f = extract_features(vid)\n",
                "            if f is not None:\n",
                "                X.append(f)\n",
                "                y.append(label)\n",
                "        except: pass\n",
                "    X, y = np.array(X), np.array(y)\n",
                "    np.save(X_PATH, X)\n",
                "    np.save(Y_PATH, y)\n",
                "    print(f\"\\n\u2705 Saved {len(X)}/{len(all_videos)}\")\n",
                "\n",
                "print(f\"Dataset: Healthy={sum(y==0)}, Lame={sum(y==1)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Training with 5-Fold CV"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
                "sc = StandardScaler()\n",
                "X_tr_s = sc.fit_transform(X_tr)\n",
                "X_te_s = sc.transform(X_te)\n",
                "print(f\"Train: {len(X_tr)} | Test: {len(X_te)}\\n\")\n",
                "\n",
                "skf = StratifiedKFold(5, shuffle=True, random_state=42)\n",
                "clfs = {\n",
                "    'LogReg': LogisticRegression(max_iter=1000, random_state=42),\n",
                "    'RF': RandomForestClassifier(n_estimators=100, random_state=42),\n",
                "    'GB': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
                "    'SVM': SVC(probability=True, random_state=42)\n",
                "}\n",
                "\n",
                "cv_res = {}\n",
                "for name, clf in clfs.items():\n",
                "    scores = []\n",
                "    for tr_i, va_i in skf.split(X_tr_s, y_tr):\n",
                "        clf.fit(X_tr_s[tr_i], y_tr[tr_i])\n",
                "        scores.append(clf.score(X_tr_s[va_i], y_tr[va_i]))\n",
                "    cv_res[name] = (np.mean(scores), np.std(scores))\n",
                "    print(f\"{name}: {np.mean(scores):.4f}\u00b1{np.std(scores):.4f}\")\n",
                "\n",
                "best = max(cv_res, key=lambda x: cv_res[x][0])\n",
                "print(f\"\\n\ud83c\udfc6 Best: {best}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train final model\n",
                "if 'RF' in best:\n",
                "    final = RandomForestClassifier(100, random_state=42)\n",
                "elif 'GB' in best:\n",
                "    final = GradientBoostingClassifier(100, random_state=42)\n",
                "elif 'SVM' in best:\n",
                "    final = SVC(probability=True, random_state=42)\n",
                "else:\n",
                "    final = LogisticRegression(max_iter=1000, random_state=42)\n",
                "\n",
                "final.fit(X_tr_s, y_tr)\n",
                "y_pred = final.predict(X_te_s)\n",
                "y_prob = final.predict_proba(X_te_s)[:,1]\n",
                "acc = accuracy_score(y_te, y_pred)\n",
                "auc = roc_auc_score(y_te, y_prob)\n",
                "\n",
                "print(f\"\\nTest Accuracy: {acc:.4f}\")\n",
                "print(f\"ROC-AUC: {auc:.4f}\\n\")\n",
                "print(classification_report(y_te, y_pred, target_names=['Saglikli','Topal']))\n",
                "\n",
                "joblib.dump(final, f\"{OUT}/models/clf_v17.pkl\")\n",
                "joblib.dump(sc, f\"{OUT}/models/scaler_v17.pkl\")\n",
                "print(\"\u2705 Model saved\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Visualizations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, ax = plt.subplots(1,2, figsize=(12,5))\n",
                "cm = confusion_matrix(y_te, y_pred)\n",
                "sns.heatmap(cm, annot=True, fmt='d', ax=ax[0], cmap='Blues',\n",
                "            xticklabels=['Healthy','Lame'], yticklabels=['Healthy','Lame'])\n",
                "ax[0].set_title(f'Confusion Matrix (Acc={acc:.3f})')\n",
                "\n",
                "fpr, tpr, _ = roc_curve(y_te, y_prob)\n",
                "ax[1].plot(fpr, tpr, lw=2, label=f'AUC={auc:.3f}')\n",
                "ax[1].plot([0,1],[0,1],'k--')\n",
                "ax[1].set_xlabel('FPR')\n",
                "ax[1].set_ylabel('TPR')\n",
                "ax[1].set_title('ROC Curve')\n",
                "ax[1].legend()\n",
                "ax[1].grid(alpha=0.3)\n",
                "plt.tight_layout()\n",
                "plt.savefig(f\"{OUT}/figures/results.png\", dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# INFERENCE WITH SAM MASKING\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Classification function\n",
                "def classify_cow(frames):\n",
                "    if len(frames)<5: return None, 0.0\n",
                "    poses = []\n",
                "    for f in frames:\n",
                "        try:\n",
                "            res = next(pose_inf(f, show=False, return_vis=False))\n",
                "            if res['predictions'] and res['predictions'][0]:\n",
                "                p = res['predictions'][0][0]\n",
                "                poses.append(np.column_stack([p['keypoints'], p['keypoint_scores']]))\n",
                "            else:\n",
                "                poses.append(np.zeros((17,3)))\n",
                "        except:\n",
                "            poses.append(np.zeros((17,3)))\n",
                "    ps = np.array(poses)\n",
                "    mf = motion_feats(ps)\n",
                "    ga = gait_angles(ps)\n",
                "    if mf is None: return None, 0.0\n",
                "    feat = np.concatenate([mf, ga]).reshape(1,-1)\n",
                "    feat_s = sc.transform(feat)\n",
                "    pred = final.predict(feat_s)[0]\n",
                "    conf = final.predict_proba(feat_s)[0][pred]\n",
                "    return pred, conf\n",
                "\n",
                "print(\"\u2705 Inference ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Process video with masking\n",
                "def process_video(vid_in, vid_out, max_fr=300, skip=3):\n",
                "    cap = cv2.VideoCapture(vid_in)\n",
                "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
                "    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
                "    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
                "    out = cv2.VideoWriter(vid_out, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w,h))\n",
                "    \n",
                "    cows = defaultdict(lambda: {'frames':[], 'preds':[], 'boxes':[]})\n",
                "    cow_id = 0\n",
                "    COLORS = {0:(0,255,0), 1:(0,0,255)}\n",
                "    LABELS = {0:\"SAGLIKLI\", 1:\"TOPAL\"}\n",
                "    \n",
                "    fr_idx = 0\n",
                "    pbar = tqdm(total=min(max_fr, int(cap.get(cv2.CAP_PROP_FRAME_COUNT))))\n",
                "    \n",
                "    while fr_idx < max_fr:\n",
                "        ret, frame = cap.read()\n",
                "        if not ret: break\n",
                "        ann = frame.copy()\n",
                "        \n",
                "        if fr_idx % skip == 0:\n",
                "            try:\n",
                "                res = next(pose_inf(frame, show=False, return_vis=False))\n",
                "                dets = res['predictions'][0] if res['predictions'] else []\n",
                "            except:\n",
                "                dets = []\n",
                "            \n",
                "            for d in dets:\n",
                "                if 'bbox' not in d or len(d['bbox'])<4: continue\n",
                "                x1,y1,x2,y2 = map(int, d['bbox'][:4])\n",
                "                crop = frame[max(0,y1):min(h,y2), max(0,x1):min(w,x2)]\n",
                "                if crop.size == 0: continue\n",
                "                \n",
                "                # Simple tracking\n",
                "                cx, cy = (x1+x2)//2, (y1+y2)//2\n",
                "                cid = None\n",
                "                min_d = 999\n",
                "                for c, hist in cows.items():\n",
                "                    if hist['boxes']:\n",
                "                        lx1,ly1,lx2,ly2 = hist['boxes'][-1]\n",
                "                        lcx, lcy = (lx1+lx2)//2, (ly1+ly2)//2\n",
                "                        d = ((cx-lcx)**2 + (cy-lcy)**2)**0.5\n",
                "                        if d<min_d and d<100:\n",
                "                            min_d, cid = d, c\n",
                "                if cid is None:\n",
                "                    cid = cow_id\n",
                "                    cow_id += 1\n",
                "                \n",
                "                cows[cid]['frames'].append(crop)\n",
                "                cows[cid]['boxes'].append([x1,y1,x2,y2])\n",
                "                \n",
                "                if len(cows[cid]['frames'])>=10:\n",
                "                    p, c = classify_cow(cows[cid]['frames'][-30:])\n",
                "                    if p is not None:\n",
                "                        cows[cid]['preds'].append((p,c))\n",
                "                \n",
                "                if cows[cid]['preds']:\n",
                "                    ps = [p[0] for p in cows[cid]['preds']]\n",
                "                    pred = max(set(ps), key=ps.count)\n",
                "                    conf = np.mean([p[1] for p in cows[cid]['preds'] if p[0]==pred])\n",
                "                else:\n",
                "                    pred, conf = 0, 0.5\n",
                "                \n",
                "                col = COLORS[pred]\n",
                "                lab = LABELS[pred]\n",
                "                \n",
                "                # SAM mask\n",
                "                try:\n",
                "                    sam_pred.set_image(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
                "                    masks, _, _ = sam_pred.predict(box=np.array([x1,y1,x2,y2]), multimask_output=False)\n",
                "                    overlay = ann.copy()\n",
                "                    overlay[masks[0]] = col\n",
                "                    ann = cv2.addWeighted(ann, 0.6, overlay, 0.4, 0)\n",
                "                except:\n",
                "                    cv2.rectangle(ann, (x1,y1), (x2,y2), col, 3)\n",
                "                \n",
                "                cv2.rectangle(ann, (x1,y1-30), (x1+200,y1), col, -1)\n",
                "                cv2.putText(ann, f\"COW {cid}: {lab} ({conf:.0%})\",\n",
                "                           (x1+5,y1-8), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2)\n",
                "        \n",
                "        out.write(ann)\n",
                "        fr_idx += 1\n",
                "        pbar.update(1)\n",
                "    \n",
                "    pbar.close()\n",
                "    cap.release()\n",
                "    out.release()\n",
                "    \n",
                "    # Results\n",
                "    res = {'total': len(cows), 'healthy': 0, 'lame': 0, 'cows': {}}\n",
                "    for cid, hist in cows.items():\n",
                "        if hist['preds']:\n",
                "            ps = [p[0] for p in hist['preds']]\n",
                "            pred = max(set(ps), key=ps.count)\n",
                "            conf = np.mean([p[1] for p in hist['preds'] if p[0]==pred])\n",
                "        else:\n",
                "            pred, conf = 0, 0.5\n",
                "        res['healthy' if pred==0 else 'lame'] += 1\n",
                "        res['cows'][cid] = {\n",
                "            'diagnosis': 'SAGLIKLI' if pred==0 else 'TOPAL',\n",
                "            'confidence': conf,\n",
                "            'frames': len(hist['frames'])\n",
                "        }\n",
                "    return res\n",
                "\n",
                "print(\"\u2705 Video processing ready\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Run Inference"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Find test video\n",
                "multi_vids = glob.glob(f\"{MULTI}/*.mp4\") if os.path.exists(MULTI) else []\n",
                "test_vid = multi_vids[0] if multi_vids else all_videos[0][0]\n",
                "print(f\"Processing: {os.path.basename(test_vid)}\\n\")\n",
                "\n",
                "out_vid = f\"{OUT}/inference_videos/result.mp4\"\n",
                "results = process_video(test_vid, out_vid, max_fr=300, skip=3)\n",
                "\n",
                "print(f\"\\n{'='*60}\")\n",
                "print(\"\ud83d\udcca RESULTS\")\n",
                "print(f\"{'='*60}\")\n",
                "print(f\"Total Cows: {results['total']}\")\n",
                "print(f\"\ud83d\udfe2 Healthy: {results['healthy']}\")\n",
                "print(f\"\ud83d\udd34 Lame: {results['lame']}\\n\")\n",
                "for cid, info in results['cows'].items():\n",
                "    e = \"\ud83d\udfe2\" if info['diagnosis']=='SAGLIKLI' else \"\ud83d\udd34\"\n",
                "    print(f\"{e} Cow {cid}: {info['diagnosis']} ({info['confidence']:.1%})\")\n",
                "print(f\"\\n\u2705 Video: {out_vid}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clinical report\n",
                "import pandas as pd\n",
                "data = [{'Cow_ID': c, **i} for c, i in results['cows'].items()]\n",
                "df = pd.DataFrame(data)\n",
                "df['confidence'] = df['confidence'].apply(lambda x: f\"{x:.2%}\")\n",
                "df.to_csv(f\"{OUT}/metrics/report.csv\", index=False)\n",
                "print(\"\ud83d\udccb CLINICAL REPORT\")\n",
                "print(df.to_string(index=False))\n",
                "print(f\"\\n\u2705 Saved: {OUT}/metrics/report.csv\")"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}